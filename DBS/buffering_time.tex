% Emacs, this is -*-latex-*-

% Buffering time

\label{sec:buffering_time}
The buffering-time, estimated by
\begin{equation}
  \label{eq:t_b}
  t_b = Bt_c,
\end{equation}
determines how long the peers must wait for start playing the
chunks. For real-time communications, $t_b$ should be as small as
possible, and to achieve this we can reduce $t_c$ and
$B$. Unfortunately, these reductions generate another drawbacks. On
the one hand, the overhead of the header of the transport protocol is
inversely proportional to $t_c$, and therefore, $t_c$ should be large
enough to keep under control this overhead. On the other hand, if $B$
is too small (for example, if $B<N^*$) the peer will not have enought
space to buffer all the chunks of a round, and due to the probability
of receiving all the chunks in order is very small, some chunks will
overwrite others before they can be played. This problem can also
happen even if $N^*\leq B<2N^*$, because the maximum jitter for a
given peer (generated by DBS) that a chunk can experiment is the sum
of the maximum jitter produced by the splitter for this peer, that can
be $N^*$, and the maximum jitter produced by the team, that also can
be $N^*$. Notice that this jitter is the same for the two extreme
topologies of the overlay: (1) a full-connected mesh
(Fig.~\ref{fig:full_mesh}) or (2) a ring (Fig.~\ref{fig:star}), and
both topologies are possible in real scenarios. Therefore, users
should select
\begin{equation}
  \label{eq:minimum_B}
  B\ge 2N^*.
\end{equation}

Given a $N$ value, DBS peers may buffer a different number of chunks
that depends on the order in which chunks are received. If $x_1$ is
the (number of the) first received chunk (the first chunk to be
played), the buffering time finishes when a chunk with number equal or
greater than $x_{1+B}$ is received.\footnote{Notice that all the
  chunks received with an number smaller than $x_1$ will be discarded,
  and that during the buffering-time, it can happens that some chunks
  are not received on time. Therefore, it does not make sense to wait
  for $B$ chunks before stopping the buffering process.} Lets analyze
some interesting cases.

Lets suppose that the first received chunk is $x_1$ and that the rest
of chunks of the buffer of size $B$ are received, being the chunk
$x_{1+B}$ the last one (this is the ideal scenario). In this case, the
stream can be played without artifacts. Because the playing of the
chunks starts after the buffering process, the start-up-time
experimented by users in the ideal case can be estimated by
\begin{equation}
  t_s = t_b + t_p,
  \label{eq:start-up-time}
\end{equation}
being $t_p$ the latency generated by the physical layer.

Imagine now one of the worst possible scenarios, in which after
receiving $x_1$ the chunk $x_{1+B}$ is received. In this case, the
chunks $x_2, \cdots x_{1+B-1}$ have been lost or delayed too much, but
again (and considering that $t_c$ is a constant), the buffering-time
is corresponds also with Eq.~\ref{eq:t_b}, because the chunk $x_{1+B}$
was generated $B$ chunk-times after $x_1$. Therefore, in this case the
start-up-time can be also estimated by Eq.~\ref{eq:start-up-time}.

After considering these two extreme situations, we can deduce that the
start-up-time does not depend on the loss chunk ratio during the
buffering-time (always that this ratio is smaller than one), but only
on $B$, $t_c$ and $t_p$. Notice that, as a rule of thumb, it holds
that the larger the buffer size, the lower the probability of lossing
chunks as a consecuence of a high $\Delta t_p$ (physical jitter).

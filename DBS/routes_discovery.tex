% Emacs, this is -*-latex-*-

% Routes Discovery and Topology Optimization

\label{sec:routes_discovery}

Chunks can be lost under bandwidth and buffering time constraints. A
chunk is lost when it is time to send it to the player, i.e. when it
is pointed by $i_p$, and the chunk has not been received. Therefore,
when a peer realizes that a chunk has been lost, nothing can be done
to recover it.

In order to mitigate this drawback, peers can pre-fetch ``potentially
lost'' chunks at the buffer position $i_p+H$, where $H\geq 0$ is the
\gls{pre-fetching_horizon}. Setting $H=0$, the pre-fetching is
disabled and only those chunks that really are lost will be
``requested''\footnote{Notice that if $H=0$, there is no time to
  recover the lost chunks. However, supposing that $\Delta t_b$ and
  $\Delta t_p$ depends on the origin of the lost chunk, we could
  request the chunk from such origin to a different neighbor, with the
  expectation of having found a faster route for such origin in the
  future.}. On the contrary, the higher the $H$, the more aggressive
the pre-fetching is.

% \leorem{Se podría ir eliminando a aquellos que no han respondido o a
% los que se les ha mandado prunning de una posible lista de donde
% coger el peer aleatorio.} -> Supongo, pero ni idea de cómo rendiría
% esto. Habría que implementarlo y experimentar.

For each (potentially, if $H>0$) lost chunk with number
$\text{lost\_chunk\_number}$, peers send a
$[\mathtt{request}~\text{lost\_chunk\_number}]$ message to a
random\footnote{An alternative to the random selection is defined in
  FCS (Sect. \ref{sec:FCS}).} peer of the team. When a peer $P_i$
receives a request message from $P_j$, $P_i$ adds $P_j$ to
$\mathtt{forward}[P_k]$, where $P_k$ is the origin peer of the chunk
stored in the position $(\text{lost\_chunk\_number}~\mathit{mod}~2B)$
of $P_i$'s buffer, in case this chunk has been received (otherwise,
the request is ignored because $P_i$ cannot determine
$P_k$). Therefore, if the requested chunk $\text{lost\_chunk\_number}$
is in $P_i$'s buffer, $P_i$ will start forwarding the chunks
originated at $P_k$ to $P_j$.

As a consequece of the request messages, redundant routes can be
created. Therefore, some chunks could be received more than once. To
avoid future chunk duplicates, peers send pruning messages to those
peers that send duplicates. The receiver $P_i$ of a
$[\mathtt{prune}~\text{duplicate\_chunk\_number}]$ message received
from $P_j$, removes $P_j$ of $\mathtt{forward}[P_k]$, where $P_k$ is
the origin peer of the chunk stored in the position
$(\text{lost\_chunk\_number}~\mathit{mod}~2B)$ of $P_i$'s buffer.

Now, we can define with more accuracy the \gls{neighborhood-degree}
(see Sec.~\ref{sec:chunk_flooding}) as the number of different
destination peers for each possible origin that a peer forwards. For
example, if a peer $P_i$ forwards chunks from the origin $P_i$ to $10$
neighbors, the neighborhood degree of $P_i$ for itself is $10$, and if
the peer $P_i$ also forwards chunks from an origin $P_j$ to $5$
neighbors, the neighborhood degree of $P_i$ for the origin $P_j$ is
$5$.

Initially, peers have, for the chunks originated in themselves, a
\gls{neighborhood-degree} equal to $K=N-1$, and the
$\mathtt{forward}[]$ table has only one entry. As long as the topology
of the overlay is optimized by the route discovery algorithm, peers
insert new entries in the forwarding table and the length of this
entry tend to be smaller. Therefore, the lists of forwarded peers for
each origin changes with the processing of the requesting and pruning
messages.

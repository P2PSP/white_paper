% Emacs, this is -*-latex-*-

% Latency of the streaming system

\label{sec:latency}

\begin{figure}
  \centering
  \vbox{\myfig{graphics/ring}{6cm}{400}}
  \caption{A ring-shaped overlay.}
  \label{fig:ring}
\end{figure}

The latency is the time required to provide a seamless playing of
the stream that travels from the source to the peers. This latency,
$t_l$, is the sum of the physical delay $t_p$ and the buffering time
$t_b$,
\begin{equation}
  \label{eq:t_l}
  t_l = t_p + t_b,
\end{equation}
where
\begin{equation}
  \label{eq:t_b}
  t_b = Bt_c,
\end{equation}
is the time that has elapsed since the peer receives two chunks
distanced $B$ positions in the buffer, being $B$ the buffer
size (in chunks), and $t_c$ the chunk time (considering $t_c$ a
constant\footnote{When $R$ is time-variying, $t_b$ would be the sum of
  the $t_c$ for each received chunk.}). Notice that Eq.~\ref{eq:t_b}
does not means that the chunks fill the buffer in order.

To minimize $t_l$, $t_b$ should be as small as possible. To achieve
this, we can reduce $t_c$ and/or $B$, but these reductions can have
negative consequences. On the one hand, $t_c$ should be large enough
to reduce the overhead of the headers used by the transport
protocol. On the other hand, if $B$ is too small (for instance $B<N$)
in a round, the peer will not have enough space to buffer all the
chunks of this round. Thus, some chunks could overwrite others before
they can be played due to a low probability of receiving chunks in
order. This problem can also happen even if $N\leq B<2N$, because the
jitter for a given peer that DBS can generate, $\Delta t_b$, that a
chunk can experiment is the sum of the jitter produced by the splitter
for this peer, that can be $N$, and the jitter produced by the
flooding of the chunk to the rest of the team, that can also be has
high as $N$. Notice that this jitter is the same for two extreme
topologies of the overlay: (1) a full-connected mesh
(Fig.~\ref{fig:full}), or (2) a ring (Fig.~\ref{fig:ring}), where the
chunks travel only in one direction\footnote{Othersize we have a
  tree.}. Therefore, peers have to use
\begin{equation}
  \label{eq:minimum_B}
  B\ge 2N^*.
\end{equation}
As a rule of thumb, the larger the buffer size the lower the
probability of losing chunks, as a consequence of a high $\Delta t_p$
(physical jitter) \leo{\{Incremento de la latencia??\}} {\color{red}
  Leo, no entiendo tu pregunta. El jitter es la variaciÃ³n de la
  latencia, que puede ser un incremento o un decremento}.

Lets analyze $t_b$ in two interesting cases. Lets suppose that the
first received chunk is $x_1$ and that the rest of chunks of the
buffer of size $B$ are received, being the chunk $x_{1+B}$ the last
one (this is the ideal scenario).\footnote{All the chunks received
  with an number smaller than $x_1$ will be discarded.} In this case,
the buffering time can still be estimated by Eq.~\ref{eq:t_b}. Lets
imagine now that after receiving $x_1$ the chunk $x_{1+B}$ is received
(chunks $x_2, \cdots x_{1+B-1}$ have been lost or delayed), and the
playing starts (probably, with severe artifacts). In this case, the
buffering time also corresponds to Eq.~\ref{eq:t_b}, because the chunk
$x_{1+B}$ was generated $B$ chunk times after $x_1$, and we cannot
wait more during the buffering time if we want to dimension
$t_b$. After considering these two extreme situations, we can deduce
that the start-up time, $t_s$, does not depend on the chunk loss ratio
during the buffering-time (for loss ratios smaller than one), but only
on $B$, $t_c$ and $t_p$.

Finally, notice that the time that passes from an incoming peer
request to join a team to a splitter until it accepts the peer, and
the buffering time that the player can require, have not been
considered in this discussion. However, both times should be, in
general, significantly lower than $t_b$, that in the case of P2PSP
corresponds to the start-up time that end-users experiment.

